{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import dataloader\n",
    "from GPT import GPT\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Loaded label dict!\n"
     ]
    }
   ],
   "source": [
    "from word_sequence import Word2Sequence\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = Word2Sequence()\n",
    "tokenizer.load_dict(config.w2s_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPT(\n",
    "    vocab_size = config.vocab_size,\n",
    "    max_len = config.max_len,\n",
    "    d_model = config.d_model,\n",
    "    nhead = config.nheads,\n",
    "    dim_feedforward = config.dim_feedforward,\n",
    "    num_layers = config.decoder_layers\n",
    ")\n",
    "gpt.to(config.device)\n",
    "gpt.load_state_dict(torch.load(\"GPT.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def select_top_k(predictions, current_loc, k=1):\n",
    "    predicted_index = random.choice(\n",
    "        predictions[0, current_loc-1, :].sort(descending=True)[1][:k]).item()\n",
    "    return predicted_index\n",
    "\n",
    "def get_curr_loc(target):\n",
    "    idx = 0\n",
    "    for i in target:\n",
    "        if i != 0:\n",
    "            idx += 1\n",
    "        else:\n",
    "            return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, x, k=1):\n",
    "    target = ['<SOS>'] + WordPunctTokenizer().tokenize(x.lower())\n",
    "    target = tokenizer.transform(target, max_len=128, pad_first=False)\n",
    "    loc = get_curr_loc(target)\n",
    "    target = torch.LongTensor(target).unsqueeze(0)\n",
    "    \n",
    "    for i in range(config.sent_length-loc-1):\n",
    "        target = target.to(config.device)\n",
    "        out = model(target)\n",
    "        pred = select_top_k(out, loc, k=k)\n",
    "        if pred == 2:\n",
    "            i -= 1\n",
    "            continue\n",
    "        target[0][loc] = pred\n",
    "        loc += 1\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS> polixenes : we know ' t , we know ' t . first citizen : let us kill him , and we ' ll have corn at our own price . is ' t a verdict ? all : no more talking on ' t ; let it be done : away , away ! second citizen : one word , good citizens . first citizen : we are accounted poor citizens , the patricians good . what authority surfeits on would relieve us : if they would yield us but the superfluity , while it were wholesome , we might guess they relieved us humanely ; but they think we are too dear : the leanness that afflicts us , the object of our misery <PAD>\n"
     ]
    }
   ],
   "source": [
    "x = \"POLIXENES:\"\n",
    "p = generate(gpt, x, k=1)\n",
    "print(\" \".join(tokenizer.inverse_transform(p.cpu()[0], is_tensor=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems like the model successfully worked... generation pretty bad, try tune up d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b44562fb7f1a4e836c26bd2df6d17a92863a39e22a29c04c28fe2e17e7662947"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
